{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMqPJcmfPcROVeYNhKIWJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NischalSuresh/mentalHealth_chatbot/blob/main/chatbot_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary libraries"
      ],
      "metadata": {
        "id": "75bN75gvW82X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "!pip install -q datasets bitsandbytes einops wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuebXeh9E0Ho",
        "outputId": "c2b9d332-64fe-48ae-8bba-f7d22718a9e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necesssary packages"
      ],
      "metadata": {
        "id": "UWEXhTI-XA7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "wq--UF8HW_8X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset Counsel_chat from huggingface (https://github.com/nbertagnolli/counsel-chat)"
      ],
      "metadata": {
        "id": "0c229QrIXuKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"nbertagnolli/counsel-chat\")\n",
        "dataset = dataset['train'].train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR8Iod-xXrcd",
        "outputId": "13b17007-9a8d-4ae8-bcff-d1ba8cef62f6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOnhFNdrYQUL",
        "outputId": "dc41a4e9-d424-4318-c599-e13b8662030c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['questionID', 'questionTitle', 'questionText', 'questionLink', 'topic', 'therapistInfo', 'therapistURL', 'answerText', 'upvotes', 'views'],\n",
              "        num_rows: 2497\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['questionID', 'questionTitle', 'questionText', 'questionLink', 'topic', 'therapistInfo', 'therapistURL', 'answerText', 'upvotes', 'views'],\n",
              "        num_rows: 278\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McnsrCIHcLqK",
        "outputId": "78a822bd-b57f-4e12-b258-5fe4093e3c40"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2497"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt template used in Llama-2 original model :\n",
        "[INST] \\<\\<SYS\\>\\>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "\\<\\</SYS\\>\\>\n",
        "{prompt}[/INST] <br>\n",
        " Source:\n",
        " - https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML\n",
        " - https://github.com/huggingface/blog/blob/main/llama2.md#fine-tuning-with-peft\n",
        "\n",
        " Refer chat_completion fn from generation.py for finetuning template - https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L45"
      ],
      "metadata": {
        "id": "Is2jw0swf2Wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format the text prompt to required format"
      ],
      "metadata": {
        "id": "dueu5djFbs1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(counsel_data):\n",
        "  output_texts = []\n",
        "  for i in range(len(counsel_data)):\n",
        "    if(counsel_data['answerText'][i]) is None:\n",
        "      pass\n",
        "    else:\n",
        "      question = (counsel_data['questionText'][i]) if (counsel_data['questionText'][i]) is not None else (counsel_data['questionTitle'][i])\n",
        "      text = f\"</s>You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.\\n### Question: {question.strip()}\\n### Answer: {(counsel_data['answerText'][i]).strip()}</s>\"\n",
        "      output_texts.append(text)\n",
        "  return output_texts"
      ],
      "metadata": {
        "id": "q5ZJnML-bsQw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check data for error (missing entries)"
      ],
      "metadata": {
        "id": "zI8M_Vi_zWqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset['train']))\n",
        "for i in range(len(dataset['train'])):\n",
        "  try:\n",
        "    question = (dataset['train']['questionText'][i]) if (dataset['train']['questionText'][i]) is not None else (dataset['train']['questionTitle'][i])\n",
        "    answer = (dataset['train']['answerText'][i])\n",
        "  except:\n",
        "    print(\"error\",i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuIygxrPstSU",
        "outputId": "ad71469b-456b-4456-9457-ad96a9db53fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = formatting_prompts_func(dataset['train'])"
      ],
      "metadata": {
        "id": "UozepIKJdDQD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check data output"
      ],
      "metadata": {
        "id": "vkszJH7920dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(out[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4jAA5lP0ZTw",
        "outputId": "808fbd72-dbaf-4f31-8d6c-5df761933b4e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "</s>You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.\n",
            "### Question: I have a fear of something and I want to face that fear to overcome it, but I don't know how. What can I do?\n",
            "### Answer: Your fear may have deeper roots within your sense of who you are, than you realize.   Fears are sometimes irrational so that logic doesn't get rid of them.Think about whether you felt secure and confident as a child.  Also, did any major bad events happen to you with other people or situations when you were growing up?Often these overwhelming situations of childhood stay with us as fears of situations in our adult lives.  If the root of the problem w the fear is from long ago, then probably a therapist who can ask you questions which help you remember upsetting childhood circumstances, may help you to dissolve the current fear.Another possibility is CBT, cognitive behavior therapy which teaches people short term mantras to do something which is safe, say being a passenger in a commercial airplane, which feels frightening to a person.CBT is short term and results are limited to specific fears.  It is a much quicker approach than self-understanding.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checking Llama format from llama-recipes"
      ],
      "metadata": {
        "id": "39y-oi_cqRaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-recipes\n"
      ],
      "metadata": {
        "id": "4zFKQuf7dTIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_recipes.utils.dataset_utils import get_preprocessed_dataset\n",
        "from llama_recipes.configs.datasets import samsum_dataset\n",
        "\n",
        "temp_dataset = get_preprocessed_dataset(tokenizer, samsum_dataset, 'train')"
      ],
      "metadata": {
        "id": "OtZEWovkneIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataset"
      ],
      "metadata": {
        "id": "y05QtzGkniXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(temp_dataset[1]['input_ids'])"
      ],
      "metadata": {
        "id": "XXatOnKjnxxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}